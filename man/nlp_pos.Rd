% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/perceptron.R
\name{nlp_pos}
\alias{nlp_pos}
\title{Read a part of speech tagging training file into a dataset}
\usage{
nlp_pos(
  sc,
  file_path,
  delimiter = NULL,
  output_pos_col = NULL,
  output_document_col = NULL,
  output_text_col = NULL
)
}
\arguments{
\item{sc}{Spark connection}

\item{file_path}{path to the text file with the training data}

\item{delimiter}{the delimiter used in the training data}

\item{output_pos_col}{the pos column name for the output data frame}

\item{output_document_col}{the document column name for the output data frame}

\item{output_text_col}{the text column name for the output data frame}
}
\value{
Spark dataframe containing the data
}
\description{
In order to train a Part of Speech Tagger annotator, we need to get corpus data as a spark dataframe.
This function does this: it reads a plain text file and transforms it to a spark dataset that is ready
for training a POS tagger.
See the Scala API docs for the default parameter values (
\url{https://nlp.johnsnowlabs.com/api/index.html#com.johnsnowlabs.nlp.training.POS)}
}
